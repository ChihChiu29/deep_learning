{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_init.py imported and reloaded\n",
      "reloaded: circular_world_env\n",
      "forwarded symbol: circular_world_env\n",
      "reloaded: environment_impl\n",
      "forwarded symbol: environment_impl\n",
      "reloaded: guided_environments\n",
      "forwarded symbol: guided_environments\n",
      "reloaded: gym\n",
      "forwarded symbol: gym\n",
      "reloaded: keras\n",
      "forwarded symbol: keras\n",
      "reloaded: layers\n",
      "forwarded symbol: layers\n",
      "reloaded: logging\n",
      "forwarded symbol: logging\n",
      "reloaded: model_builder\n",
      "forwarded symbol: model_builder\n",
      "reloaded: models\n",
      "forwarded symbol: models\n",
      "reloaded: numpy\n",
      "forwarded symbol: numpy\n",
      "reloaded: numpy_util\n",
      "forwarded symbol: numpy_util\n",
      "reloaded: optimizers\n",
      "forwarded symbol: optimizers\n",
      "reloaded: policy_impl\n",
      "forwarded symbol: policy_impl\n",
      "reloaded: q_base\n",
      "forwarded symbol: q_base\n",
      "reloaded: qfunc_impl\n",
      "forwarded symbol: qfunc_impl\n",
      "reloaded: runner_extension_impl\n",
      "forwarded symbol: runner_extension_impl\n",
      "reloaded: runner_impl\n",
      "forwarded symbol: runner_impl\n",
      "reloaded: shortcut\n",
      "forwarded symbol: shortcut\n"
     ]
    }
   ],
   "source": [
    "ReloadProject('deep_learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN_WithTargetNextwork, (20, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = shortcut.FullRunPipeline(gym_env_name='LunarLander-v2', model_shape=(20, 20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:40] logging.py:44 Episode 100/5000: avg_reward = -162.06, avg_steps=96.27 (over 100 episodes)\n",
      "[21:53:59] logging.py:44 Episode 200/5000: avg_reward = -142.57, avg_steps=106.01 (over 100 episodes)\n",
      "[21:54:26] logging.py:44 Episode 300/5000: avg_reward = -109.54, avg_steps=124.89 (over 100 episodes)\n",
      "[21:54:51] logging.py:44 Episode 400/5000: avg_reward = -95.60, avg_steps=131.27 (over 100 episodes)\n",
      "[21:55:35] logging.py:44 Episode 500/5000: avg_reward = -68.15, avg_steps=175.71 (over 100 episodes)\n",
      "[21:56:44] logging.py:44 Episode 600/5000: avg_reward = -62.49, avg_steps=280.82 (over 100 episodes)\n",
      "[21:58:19] logging.py:44 Episode 700/5000: avg_reward = -49.51, avg_steps=356.80 (over 100 episodes)\n",
      "[22:00:29] logging.py:44 Episode 800/5000: avg_reward = -70.10, avg_steps=451.57 (over 100 episodes)\n",
      "[22:03:48] logging.py:44 Episode 900/5000: avg_reward = -28.57, avg_steps=650.45 (over 100 episodes)\n",
      "[22:07:04] logging.py:44 Episode 1000/5000: avg_reward = 2.95, avg_steps=643.47 (over 100 episodes)\n",
      "[22:10:59] logging.py:44 Episode 1100/5000: avg_reward = 65.67, avg_steps=763.01 (over 100 episodes)\n",
      "[22:14:34] logging.py:44 Episode 1200/5000: avg_reward = 86.20, avg_steps=714.46 (over 100 episodes)\n",
      "[22:17:38] logging.py:44 Episode 1300/5000: avg_reward = 118.79, avg_steps=626.54 (over 100 episodes)\n",
      "[22:21:05] logging.py:44 Episode 1400/5000: avg_reward = 123.41, avg_steps=669.53 (over 100 episodes)\n",
      "[22:23:54] logging.py:44 Episode 1500/5000: avg_reward = 117.31, avg_steps=562.04 (over 100 episodes)\n",
      "[22:26:46] logging.py:44 Episode 1600/5000: avg_reward = 146.14, avg_steps=648.21 (over 100 episodes)\n",
      "[22:29:06] logging.py:44 Episode 1700/5000: avg_reward = 181.02, avg_steps=528.91 (over 100 episodes)\n",
      "[22:31:21] logging.py:44 Episode 1800/5000: avg_reward = 154.53, avg_steps=523.14 (over 100 episodes)\n",
      "[22:33:36] logging.py:44 Episode 1900/5000: avg_reward = 169.12, avg_steps=481.96 (over 100 episodes)\n",
      "[22:35:36] logging.py:44 Episode 2000/5000: avg_reward = 141.25, avg_steps=456.34 (over 100 episodes)\n",
      "[22:37:41] logging.py:44 Episode 2100/5000: avg_reward = 194.45, avg_steps=469.26 (over 100 episodes)\n",
      "[22:39:44] logging.py:44 Episode 2200/5000: avg_reward = 221.58, avg_steps=482.84 (over 100 episodes)\n",
      "[22:41:40] logging.py:44 Episode 2300/5000: avg_reward = 229.36, avg_steps=437.78 (over 100 episodes)\n",
      "[22:43:21] logging.py:44 Episode 2400/5000: avg_reward = 224.55, avg_steps=408.64 (over 100 episodes)\n",
      "[22:45:02] logging.py:44 Episode 2500/5000: avg_reward = 222.50, avg_steps=407.27 (over 100 episodes)\n",
      "[22:46:54] logging.py:44 Episode 2600/5000: avg_reward = 225.59, avg_steps=421.44 (over 100 episodes)\n",
      "[22:48:48] logging.py:44 Episode 2700/5000: avg_reward = 228.43, avg_steps=437.57 (over 100 episodes)\n",
      "[22:50:22] logging.py:44 Episode 2800/5000: avg_reward = 230.26, avg_steps=375.98 (over 100 episodes)\n",
      "[22:52:07] logging.py:44 Episode 2900/5000: avg_reward = 249.49, avg_steps=396.90 (over 100 episodes)\n",
      "[22:53:39] logging.py:44 Episode 3000/5000: avg_reward = 241.75, avg_steps=373.94 (over 100 episodes)\n",
      "[22:55:11] logging.py:44 Episode 3100/5000: avg_reward = 240.60, avg_steps=375.49 (over 100 episodes)\n",
      "[22:56:49] logging.py:44 Episode 3200/5000: avg_reward = 229.56, avg_steps=396.21 (over 100 episodes)\n",
      "[22:58:21] logging.py:44 Episode 3300/5000: avg_reward = 256.54, avg_steps=376.53 (over 100 episodes)\n",
      "[23:00:00] logging.py:44 Episode 3400/5000: avg_reward = 260.50, avg_steps=401.51 (over 100 episodes)\n",
      "[23:02:23] logging.py:44 Episode 3500/5000: avg_reward = 234.89, avg_steps=427.90 (over 100 episodes)\n",
      "[23:04:14] logging.py:44 Episode 3600/5000: avg_reward = 221.83, avg_steps=365.54 (over 100 episodes)\n",
      "[23:05:25] logging.py:44 Episode 3700/5000: avg_reward = 191.07, avg_steps=269.91 (over 100 episodes)\n",
      "[23:06:30] logging.py:44 Episode 3800/5000: avg_reward = 150.68, avg_steps=249.23 (over 100 episodes)\n",
      "[23:08:11] logging.py:44 Episode 3900/5000: avg_reward = 180.28, avg_steps=371.16 (over 100 episodes)\n",
      "[23:09:41] logging.py:44 Episode 4000/5000: avg_reward = 169.95, avg_steps=343.56 (over 100 episodes)\n",
      "[23:11:53] logging.py:44 Episode 4100/5000: avg_reward = 103.82, avg_steps=411.34 (over 100 episodes)\n",
      "[23:13:03] logging.py:44 Episode 4200/5000: avg_reward = 113.62, avg_steps=234.41 (over 100 episodes)\n",
      "[23:13:55] logging.py:44 Episode 4300/5000: avg_reward = -21.27, avg_steps=204.38 (over 100 episodes)\n",
      "[23:15:29] logging.py:44 Episode 4400/5000: avg_reward = 136.72, avg_steps=334.25 (over 100 episodes)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c771e949b88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/external/deep_learning/engine/shortcut.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, num_of_episodes)\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mqfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       num_of_episodes=num_of_episodes)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mDemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_episodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_video_to\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'demo.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/external/deep_learning/engine/q_base.py\u001b[0m in \u001b[0;36mRun\u001b[0;34m(self, env, qfunc, policy, num_of_episodes)\u001b[0m\n",
      "\u001b[0;32m/workspace/external/deep_learning/engine/runner_extension_impl.py\u001b[0m in \u001b[0;36mOnEpisodeFinishedCallback\u001b[0;34m(self, env, qfunc, episode_idx, num_of_episodes, episode_reward, steps)\u001b[0m\n\u001b[1;32m     56\u001b[0m         float(numpy.mean(\n\u001b[1;32m     57\u001b[0m           self._episode_steps[-self._report_every_num_of_episodes:])),\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_every_num_of_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m       )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/external/qpylib/logging.py\u001b[0m in \u001b[0;36mprintf\u001b[0;34m(msg, *args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m   \u001b[0mvlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/external/qpylib/logging.py\u001b[0m in \u001b[0;36mvlog\u001b[0;34m(verbosity, msg, *args)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mcaller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   prefix = '[%s] %s:%s ' % (\n\u001b[1;32m     37\u001b[0m     \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1450\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1452\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mpat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^(\\s*def\\s)|(\\s*async\\s+def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m             \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pipeline.Train(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDQN, (20, 20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = shortcut.FullRunPipeline(gym_env_name='LunarLander-v2', model_shape=(20, 20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:06:39] logging.py:44 Episode 100/5000: avg_reward = -167.57, avg_steps=105.33 (over 100 episodes)\n",
      "[01:07:04] logging.py:44 Episode 200/5000: avg_reward = -132.49, avg_steps=112.12 (over 100 episodes)\n",
      "[01:07:30] logging.py:44 Episode 300/5000: avg_reward = -92.69, avg_steps=119.44 (over 100 episodes)\n",
      "[01:08:05] logging.py:44 Episode 400/5000: avg_reward = -79.87, avg_steps=150.36 (over 100 episodes)\n",
      "[01:08:42] logging.py:44 Episode 500/5000: avg_reward = -60.31, avg_steps=164.35 (over 100 episodes)\n",
      "[01:09:41] logging.py:44 Episode 600/5000: avg_reward = -48.98, avg_steps=241.54 (over 100 episodes)\n",
      "[01:12:01] logging.py:44 Episode 700/5000: avg_reward = -29.57, avg_steps=447.09 (over 100 episodes)\n",
      "[01:15:14] logging.py:44 Episode 800/5000: avg_reward = 27.09, avg_steps=587.21 (over 100 episodes)\n",
      "[01:17:32] logging.py:44 Episode 900/5000: avg_reward = 35.94, avg_steps=455.11 (over 100 episodes)\n",
      "[01:19:57] logging.py:44 Episode 1000/5000: avg_reward = 26.58, avg_steps=475.85 (over 100 episodes)\n",
      "[01:22:17] logging.py:44 Episode 1100/5000: avg_reward = 20.97, avg_steps=449.29 (over 100 episodes)\n",
      "[01:26:00] logging.py:44 Episode 1200/5000: avg_reward = 66.46, avg_steps=728.90 (over 100 episodes)\n",
      "[01:29:30] logging.py:44 Episode 1300/5000: avg_reward = 70.04, avg_steps=672.50 (over 100 episodes)\n",
      "[01:33:21] logging.py:44 Episode 1400/5000: avg_reward = 85.22, avg_steps=713.90 (over 100 episodes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.115544). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:37:11] logging.py:44 Episode 1500/5000: avg_reward = 101.37, avg_steps=696.73 (over 100 episodes)\n",
      "[01:41:09] logging.py:44 Episode 1600/5000: avg_reward = 148.29, avg_steps=637.26 (over 100 episodes)\n",
      "[01:44:39] logging.py:44 Episode 1700/5000: avg_reward = 126.76, avg_steps=562.50 (over 100 episodes)\n",
      "[01:47:41] logging.py:44 Episode 1800/5000: avg_reward = 115.01, avg_steps=530.56 (over 100 episodes)\n",
      "[01:51:16] logging.py:44 Episode 1900/5000: avg_reward = 149.78, avg_steps=571.55 (over 100 episodes)\n",
      "[01:53:59] logging.py:44 Episode 2000/5000: avg_reward = 127.67, avg_steps=439.90 (over 100 episodes)\n",
      "[01:57:37] logging.py:44 Episode 2100/5000: avg_reward = 120.16, avg_steps=567.23 (over 100 episodes)\n",
      "[02:01:03] logging.py:44 Episode 2200/5000: avg_reward = 159.93, avg_steps=579.86 (over 100 episodes)\n",
      "[02:04:46] logging.py:44 Episode 2300/5000: avg_reward = 175.26, avg_steps=631.76 (over 100 episodes)\n",
      "[02:07:38] logging.py:44 Episode 2400/5000: avg_reward = 180.95, avg_steps=516.75 (over 100 episodes)\n",
      "[02:10:04] logging.py:44 Episode 2500/5000: avg_reward = 197.36, avg_steps=432.92 (over 100 episodes)\n"
     ]
    }
   ],
   "source": [
    "pipeline.Train(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf = pipeline.qfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf._q1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
