{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook_init.py imported and reloaded\n",
      "reloaded: circular_world_env\n",
      "forwarded symbol: circular_world_env\n",
      "reloaded: environment_impl\n",
      "forwarded symbol: environment_impl\n",
      "reloaded: guided_environments\n",
      "forwarded symbol: guided_environments\n",
      "reloaded: gym\n",
      "forwarded symbol: gym\n",
      "reloaded: keras\n",
      "forwarded symbol: keras\n",
      "reloaded: layers\n",
      "forwarded symbol: layers\n",
      "reloaded: logging\n",
      "forwarded symbol: logging\n",
      "reloaded: model_builder\n",
      "forwarded symbol: model_builder\n",
      "reloaded: models\n",
      "forwarded symbol: models\n",
      "reloaded: numpy\n",
      "forwarded symbol: numpy\n",
      "reloaded: numpy_util\n",
      "forwarded symbol: numpy_util\n",
      "reloaded: optimizers\n",
      "forwarded symbol: optimizers\n",
      "reloaded: policy_impl\n",
      "forwarded symbol: policy_impl\n",
      "reloaded: q_base\n",
      "forwarded symbol: q_base\n",
      "reloaded: qfunc_impl\n",
      "forwarded symbol: qfunc_impl\n",
      "reloaded: runner_extension_impl\n",
      "forwarded symbol: runner_extension_impl\n",
      "reloaded: runner_impl\n",
      "forwarded symbol: runner_impl\n",
      "reloaded: shortcut\n",
      "forwarded symbol: shortcut\n"
     ]
    }
   ],
   "source": [
    "ReloadProject('deep_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:17] c:\\Workspace\\git\\qpylib\\logging.py:44 Using qfunc implementation: DQN_TargetNetwork\n",
      "[19:12:17] c:\\Workspace\\git\\qpylib\\logging.py:44 Using policy implementation: GreedyPolicyWithDecreasingRandomness\n",
      "[19:12:17] c:\\Workspace\\git\\qpylib\\logging.py:44 Using runner implementation: ExperienceReplayRunner\n"
     ]
    }
   ],
   "source": [
    "pipeline = shortcut.ScreenLearningPipeline(\n",
    "    gym_env_name='MsPacman-v0',\n",
    "    report_every_num_of_episodes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x1ea670bbcc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e93a15bdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e93a1847f0>,\n",
       " <keras.layers.core.Flatten at 0x1e93a19fef0>,\n",
       " <keras.layers.core.Dense at 0x1e93a1bb128>,\n",
       " <keras.layers.core.Dense at 0x1e93a1d0d30>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.qfunc._model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:02] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 10/3000: avg_reward = 216.00, avg_steps=631.70 (over 10 episodes)\n",
      "[19:24:36] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 20/3000: avg_reward = 197.00, avg_steps=644.80 (over 10 episodes)\n",
      "[19:31:20] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 30/3000: avg_reward = 292.00, avg_steps=702.10 (over 10 episodes)\n",
      "[19:38:29] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 40/3000: avg_reward = 285.00, avg_steps=665.70 (over 10 episodes)\n",
      "[19:46:23] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 50/3000: avg_reward = 273.00, avg_steps=643.40 (over 10 episodes)\n",
      "[19:56:21] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 60/3000: avg_reward = 302.00, avg_steps=696.30 (over 10 episodes)\n",
      "[20:07:38] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 70/3000: avg_reward = 346.00, avg_steps=669.10 (over 10 episodes)\n",
      "[20:19:43] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 80/3000: avg_reward = 248.00, avg_steps=632.00 (over 10 episodes)\n",
      "[20:34:13] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 90/3000: avg_reward = 387.00, avg_steps=679.70 (over 10 episodes)\n",
      "[20:54:18] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 100/3000: avg_reward = 373.00, avg_steps=718.40 (over 10 episodes)\n",
      "[21:11:33] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 110/3000: avg_reward = 318.00, avg_steps=641.70 (over 10 episodes)\n",
      "[21:29:30] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 120/3000: avg_reward = 404.00, avg_steps=635.60 (over 10 episodes)\n",
      "[21:50:07] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 130/3000: avg_reward = 299.00, avg_steps=690.90 (over 10 episodes)\n",
      "[22:12:11] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 140/3000: avg_reward = 376.00, avg_steps=695.90 (over 10 episodes)\n",
      "[22:35:11] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 150/3000: avg_reward = 338.00, avg_steps=671.20 (over 10 episodes)\n",
      "[23:09:13] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 160/3000: avg_reward = 333.00, avg_steps=670.90 (over 10 episodes)\n",
      "[23:44:11] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 170/3000: avg_reward = 436.00, avg_steps=712.40 (over 10 episodes)\n",
      "[00:14:55] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 180/3000: avg_reward = 379.00, avg_steps=640.90 (over 10 episodes)\n",
      "[00:51:25] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 190/3000: avg_reward = 519.00, avg_steps=784.70 (over 10 episodes)\n",
      "[01:22:36] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 200/3000: avg_reward = 389.00, avg_steps=696.20 (over 10 episodes)\n",
      "[01:52:09] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 210/3000: avg_reward = 339.00, avg_steps=678.30 (over 10 episodes)\n",
      "[02:24:23] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 220/3000: avg_reward = 457.00, avg_steps=765.30 (over 10 episodes)\n",
      "[02:53:41] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 230/3000: avg_reward = 398.00, avg_steps=721.40 (over 10 episodes)\n",
      "[03:26:33] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 240/3000: avg_reward = 480.00, avg_steps=842.20 (over 10 episodes)\n",
      "[03:51:54] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 250/3000: avg_reward = 366.00, avg_steps=678.70 (over 10 episodes)\n",
      "[04:20:38] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 260/3000: avg_reward = 551.00, avg_steps=798.00 (over 10 episodes)\n",
      "[04:45:52] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 270/3000: avg_reward = 555.00, avg_steps=737.90 (over 10 episodes)\n",
      "[05:06:49] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 280/3000: avg_reward = 370.00, avg_steps=645.50 (over 10 episodes)\n",
      "[05:30:02] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 290/3000: avg_reward = 496.00, avg_steps=747.30 (over 10 episodes)\n",
      "[05:51:34] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 300/3000: avg_reward = 401.00, avg_steps=694.50 (over 10 episodes)\n",
      "[06:16:24] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 310/3000: avg_reward = 529.00, avg_steps=778.70 (over 10 episodes)\n",
      "[06:43:54] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 320/3000: avg_reward = 654.00, avg_steps=853.90 (over 10 episodes)\n",
      "[07:07:46] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 330/3000: avg_reward = 587.00, avg_steps=737.30 (over 10 episodes)\n",
      "[07:30:33] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 340/3000: avg_reward = 480.00, avg_steps=708.30 (over 10 episodes)\n",
      "[07:56:29] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 350/3000: avg_reward = 646.00, avg_steps=802.00 (over 10 episodes)\n",
      "[08:19:31] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 360/3000: avg_reward = 449.00, avg_steps=711.30 (over 10 episodes)\n",
      "[08:44:43] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 370/3000: avg_reward = 522.00, avg_steps=780.80 (over 10 episodes)\n",
      "[09:07:56] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 380/3000: avg_reward = 549.00, avg_steps=702.10 (over 10 episodes)\n",
      "[09:33:53] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 390/3000: avg_reward = 573.00, avg_steps=814.40 (over 10 episodes)\n",
      "[09:56:14] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 400/3000: avg_reward = 500.00, avg_steps=712.50 (over 10 episodes)\n",
      "[10:17:59] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 410/3000: avg_reward = 580.00, avg_steps=695.10 (over 10 episodes)\n",
      "[10:43:38] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 420/3000: avg_reward = 831.00, avg_steps=825.90 (over 10 episodes)\n",
      "[11:04:56] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 430/3000: avg_reward = 461.00, avg_steps=693.30 (over 10 episodes)\n",
      "[11:27:15] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 440/3000: avg_reward = 391.00, avg_steps=732.10 (over 10 episodes)\n",
      "[11:49:09] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 450/3000: avg_reward = 451.00, avg_steps=721.90 (over 10 episodes)\n",
      "[12:16:38] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 460/3000: avg_reward = 876.00, avg_steps=905.20 (over 10 episodes)\n",
      "[12:37:50] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 470/3000: avg_reward = 524.00, avg_steps=704.20 (over 10 episodes)\n",
      "[12:59:18] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 480/3000: avg_reward = 506.00, avg_steps=719.90 (over 10 episodes)\n",
      "[13:21:30] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 490/3000: avg_reward = 547.00, avg_steps=744.80 (over 10 episodes)\n",
      "[13:47:14] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 500/3000: avg_reward = 650.00, avg_steps=865.40 (over 10 episodes)\n",
      "[14:06:21] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 510/3000: avg_reward = 469.00, avg_steps=648.00 (over 10 episodes)\n",
      "[14:28:47] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 520/3000: avg_reward = 622.00, avg_steps=763.80 (over 10 episodes)\n",
      "[14:51:28] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 530/3000: avg_reward = 575.00, avg_steps=782.80 (over 10 episodes)\n",
      "[15:10:33] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 540/3000: avg_reward = 419.00, avg_steps=662.80 (over 10 episodes)\n",
      "[15:35:44] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 550/3000: avg_reward = 769.00, avg_steps=875.00 (over 10 episodes)\n",
      "[15:58:43] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 560/3000: avg_reward = 627.00, avg_steps=756.70 (over 10 episodes)\n",
      "[16:21:01] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 570/3000: avg_reward = 652.00, avg_steps=722.80 (over 10 episodes)\n",
      "[16:44:56] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 580/3000: avg_reward = 501.00, avg_steps=770.90 (over 10 episodes)\n",
      "[17:14:06] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 590/3000: avg_reward = 612.00, avg_steps=747.50 (over 10 episodes)\n",
      "[17:52:03] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 600/3000: avg_reward = 569.00, avg_steps=811.30 (over 10 episodes)\n",
      "[18:33:15] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 610/3000: avg_reward = 751.00, avg_steps=738.40 (over 10 episodes)\n",
      "[19:12:09] c:\\Workspace\\git\\qpylib\\logging.py:44 Episode 620/3000: avg_reward = 659.00, avg_steps=846.10 (over 10 episodes)\n"
     ]
    }
   ],
   "source": [
    "pipeline.Train(num_of_episodes=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
